{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nl6KtsXWQRnc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import warnings\n",
        "import joblib\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Fetch dataset\n",
        "breast_cancer = fetch_ucirepo(id=17)\n",
        "X = breast_cancer.data.features\n",
        "y = breast_cancer.data.targets.squeeze()\n",
        "\n",
        "# Encode labels dynamically\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "class_names = le.classes_.tolist()\n",
        "\n",
        "# Data exploration\n",
        "print(X.head(), y[:5])\n",
        "print(\"Missing Values:\", X.isnull().sum().sum())\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert back to DataFrame for feature selection\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Feature selection using RandomForest feature importance\n",
        "selector = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "selector.fit(X_scaled, y)\n",
        "feature_importances = pd.Series(selector.feature_importances_, index=X.columns)\n",
        "selected_features = feature_importances.nlargest(15).index\n",
        "X_selected = X_scaled_df[selected_features].values\n",
        "\n",
        "# Visualize Feature Importance\n",
        "plt.figure(figsize=(10, 5))\n",
        "feature_importances.sort_values().plot(kind='barh', color='skyblue')\n",
        "plt.title(\"Feature Importances from Random Forest\")\n",
        "plt.show()\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Class distribution\n",
        "sns.countplot(x=pd.Series(y))\n",
        "plt.title(\"Distribution of Classes\")\n",
        "plt.show()\n",
        "\n",
        "# Correlation matrix\n",
        "sns.heatmap(X_scaled_df.corr(), cmap=\"coolwarm\")\n",
        "plt.title(\"Feature Correlation Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Model evaluation\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"SVM\": SVC(kernel='linear'),\n",
        "    \"k-NN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"XGBoost\": XGBClassifier(objective='binary:logistic', eval_metric='logloss', verbosity=0)\n",
        "}\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='accuracy')\n",
        "    print(f\"{name} Accuracy: {np.mean(scores):.4f}\")\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "random_search = RandomizedSearchCV(RandomForestClassifier(), param_dist, cv=5, n_iter=10, scoring='accuracy', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# Train best model with best parameters\n",
        "best_params = random_search.best_params_\n",
        "best_tuned_model = RandomForestClassifier(**best_params, random_state=42)\n",
        "best_tuned_model.fit(X_train, y_train)\n",
        "y_pred = best_tuned_model.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "print(df_report)\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# SHAP Explainability\n",
        "explainer = shap.Explainer(best_tuned_model, X_train)\n",
        "shap_values = explainer(X_test)\n",
        "shap.summary_plot(shap_values, X_test)\n",
        "\n",
        "# LIME Explainability\n",
        "explainer_lime = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X_train, feature_names=selected_features, class_names=class_names, mode='classification')\n",
        "exp = explainer_lime.explain_instance(X_test[0], best_tuned_model.predict_proba)\n",
        "exp.show_in_notebook()\n",
        "\n",
        "# Save model\n",
        "joblib.dump(best_tuned_model, \"breast_cancer_tuned_model.pkl\")"
      ]
    }
  ]
}